In this section we present the results for the various policies when run across various regimes with different $\theta$ and $p$ values. Particularly, we present results when $\theta \in \{0.2, 0.4, 0.6, 0.8\}$, and for $p \in [0,1]$. To maintain the same scale across varying $\theta$ values, we present the results in relative terms of proportion of optimal score achieved. More specifically, for a $G_\theta$ the theoretical optimal score is when all positive target nodes are reached, and all negative nodes are avoided. Obviously, this is not always actually possible. However, it does provide an upper bound on the possible score and lets us present the results in relative scores.


